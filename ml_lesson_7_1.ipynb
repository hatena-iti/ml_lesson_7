{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みニューラルネットワーク (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./capture/ml_lesson_7_1_capture01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section2 CNNを使ったモデルを構築してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fashion MNIST(白黒画像)をCNNでクラス分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 15))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n",
    "                    wspace=0.05)\n",
    "\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(1, 9, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(x_train[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このとき読み込んだ画像は(バッチサイズ、縦の画素数、 横の画素数)の次元で表されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)) / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)) / 255\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前章の多層パーセプトロンでは入力を (バッチサイズ、画素数) の2次元テンソルとして扱いましたが、 CNNでは2次元の画像として処理していくために4次元テンソル (バッチサイズ、縦の画素数、横の画素数、チャンネル数)として扱います。 チャンネル数は白黒画像の場合は1、 カラー画像の場合はRGBで3です。\n",
    "\n",
    "Fashion MNISTの画像は白黒データですのでチャンネル数を1に設定しています。(カラー画像の場合はチャンネル数が3になります)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 入力画像 28x28x1 (縦の画素数)x(横の画素数)x(チャンネル数)\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(28, 28, 1)))  # 28x28x1 -> 24x24x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 24x24x16 -> 12x12x16\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 12x12x16 -> 8x8x64\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 8x8x64 -> 4x4x64\n",
    "\n",
    "model.add(Flatten())  # 4x4x64-> 1024\n",
    "model.add(Dense(10, activation='softmax'))  # 1024 -> 10\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成したモデルを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習を実行\n",
    "# 実行時間の都合上、 epoch 数＝3 とする\n",
    "# EarlyStopping：　過学習を防止するための仕組み。学習の精度が上がらなくなった段階で実行を停止する\n",
    "early_stopping = EarlyStopping(patience=1, verbose=1)\n",
    "#model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, verbose=1,\n",
    "#          validation_split=0.1, callbacks=[early_stopping])\n",
    "model.fit(x=x_train, y=y_train, batch_size=32, epochs=3, verbose=1,\n",
    "          validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# 性能評価（ loss：　予測結果と正解との誤差、accuracy：　正解率）\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 CIFAR10のデータ(カラー画像)をCNNでクラス分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.2.1 データセットの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6万枚のカラー画像に10のカテゴリのどれかが付与されたCIFAR-10というデータセットを使用します。\n",
    "\n",
    "まず、データを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "y_train = np.eye(10)[y_train.astype('int32').flatten()]\n",
    "\n",
    "x_test = x_test.astype('float32') / 255\n",
    "y_test = np.eye(10)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像はRGBデータなのでFashion MNISTとは異なり、チャンネル数は3になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、CIFAR-10の画像の例を表示してみます。この画像ひとつひとつに10のカテゴリのうちひとつが付与されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 15))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n",
    "                    wspace=0.05)\n",
    "\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(1, 9, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(x_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のネットワークを実装してみます。\n",
    "\n",
    "![](./figures/lenet.png)\n",
    "\n",
    "Y. LeCun et al., \"Gradient-based learning applied to document recognition\", Proceedings of the IEEE, 1998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(120, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->120\n",
    "model.add(Dense(84, activation='relu', kernel_initializer='he_normal'))  # 120 ->84\n",
    "model.add(Dense(10, activation='softmax'))  # 84 ->10\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成したモデルを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習を実行\n",
    "# 実行時間の都合上、 epoch 数＝3 とする\n",
    "# EarlyStopping：　過学習を防止するための仕組み。学習の精度が上がらなくなった段階で実行を停止する\n",
    "early_stopping = EarlyStopping(patience=1, verbose=1)\n",
    "#model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, verbose=1,\n",
    "#          validation_data=(x_valid, y_valid), callbacks=[early_stopping])\n",
    "model.fit(x=x_train, y=y_train, batch_size=32, epochs=3, verbose=1,\n",
    "          validation_data=(x_valid, y_valid), callbacks=[early_stopping])\n",
    "\n",
    "# 性能評価（ loss：　予測結果と正解との誤差、accuracy：　正解率）\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ファインチューニング（ fine-tuning ）\n",
    "\n",
    "## ファインチューニング、転移学習とは\n",
    "\n",
    "![](./capture/ml_lesson_7_1_capture03.png)\n",
    "\n",
    "## Keras で使える学習済みモデル\n",
    "\n",
    "![](./capture/ml_lesson_7_1_capture02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10のデータ(カラー画像)を MobileNet のファインチューニングでクラス分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet モデルのライブラリを読み込む\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "\n",
    "# 入力フォーマット\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "# MobileNet モデルを定義\n",
    "base_model = MobileNet(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# 全結合層の新規構築\n",
    "top_model = base_model.output\n",
    "top_model = Flatten()(top_model)\n",
    "#top_model = GlobalAveragePooling2D()(top_model) # Flatten の代わりに GlobalAveragePooling2D も有効であるとのこと\n",
    "top_model = Dense(1024, activation = 'relu')(top_model)\n",
    "predictions = Dense(10, activation = 'softmax')(top_model)\n",
    "\n",
    "# ネットワーク全体の定義\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# MobileNet の conv_dw_13 層の手前までは再学習させない\n",
    "trainable = False\n",
    "for layer in model.layers:\n",
    "    if layer.name == 'conv_dw_13':\n",
    "        trainable = True\n",
    "    \n",
    "    # conv_dw_13 以降の層は freeze 解除\n",
    "    layer.trainable = trainable\n",
    "\n",
    "    # ただし、conv_dw_13　以前の層でも、Batch Normalization 層は再学習させる\n",
    "    if layer.name.endswith('bn'):\n",
    "        layer.trainable = True\n",
    "\n",
    "#\n",
    "print(\"MobileNet {}層\".format(len(model.layers)))\n",
    "\n",
    "#\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習を実行\n",
    "# 実行時間の都合上、 epoch 数＝3 とする\n",
    "# EarlyStopping：　過学習を防止するための仕組み。学習の精度が上がらなくなった段階で実行を停止する\n",
    "early_stopping = EarlyStopping(patience=1, verbose=1)\n",
    "#model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, verbose=1,\n",
    "#          validation_data=(x_valid, y_valid), callbacks=[early_stopping])\n",
    "model.fit(x=x_train, y=y_train, batch_size=32, epochs=3, verbose=1,\n",
    "          validation_data=(x_valid, y_valid), callbacks=[early_stopping])\n",
    "\n",
    "# 性能評価（ loss：　予測結果と正解との誤差、accuracy：　正解率）\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
